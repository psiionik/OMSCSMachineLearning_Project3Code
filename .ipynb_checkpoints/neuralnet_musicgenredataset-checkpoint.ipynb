{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd0ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path  import join\n",
    "import random as rn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import log_loss\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.random_projection import SparseRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9731c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       popularity  acousticness  danceability  duration_ms  energy  \\\n",
      "0            27.0       0.00468         0.652         -1.0   0.941   \n",
      "1            31.0       0.01270         0.622     218293.0   0.890   \n",
      "2            28.0       0.00306         0.620     215613.0   0.755   \n",
      "3            34.0       0.02540         0.774     166875.0   0.700   \n",
      "4            32.0       0.00465         0.638     222369.0   0.587   \n",
      "...           ...           ...           ...          ...     ...   \n",
      "49995        59.0       0.03340         0.913         -1.0   0.574   \n",
      "49996        72.0       0.15700         0.709     251860.0   0.362   \n",
      "49997        51.0       0.00597         0.693     189483.0   0.763   \n",
      "49998        65.0       0.08310         0.782     262773.0   0.472   \n",
      "49999        67.0       0.10200         0.862     267267.0   0.642   \n",
      "\n",
      "       instrumentalness  key  liveness  loudness  mode  speechiness   tempo  \\\n",
      "0               0.79200    1     0.115    -5.201     1       0.0748  100.89   \n",
      "1               0.95000    5     0.124    -7.043     1       0.0300  115.00   \n",
      "2               0.01180   11     0.534    -4.617     0       0.0345  127.99   \n",
      "3               0.00253    4     0.157    -4.498     0       0.2390  128.01   \n",
      "4               0.90900    9     0.157    -6.266     0       0.0413  145.04   \n",
      "...                 ...  ...       ...       ...   ...          ...     ...   \n",
      "49995           0.00000    4     0.119    -7.022     0       0.2980   98.03   \n",
      "49996           0.00000    2     0.109    -9.814     0       0.0550  122.04   \n",
      "49997           0.00000    5     0.143    -5.443     0       0.1460  131.08   \n",
      "49998           0.00000   10     0.106    -5.016     1       0.0441   75.89   \n",
      "49999           0.00000    9     0.272   -13.652     1       0.1010   99.20   \n",
      "\n",
      "       valence music_genre  \n",
      "0        0.759  Electronic  \n",
      "1        0.531  Electronic  \n",
      "2        0.333  Electronic  \n",
      "3        0.270  Electronic  \n",
      "4        0.323  Electronic  \n",
      "...        ...         ...  \n",
      "49995    0.330     Hip-Hop  \n",
      "49996    0.113     Hip-Hop  \n",
      "49997    0.395     Hip-Hop  \n",
      "49998    0.354     Hip-Hop  \n",
      "49999    0.765     Hip-Hop  \n",
      "\n",
      "[45020 rows x 14 columns]\n",
      "['Alternative' 'Anime' 'Blues' 'Classical' 'Country' 'Electronic'\n",
      " 'Hip-Hop' 'Jazz' 'Rap' 'Rock']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading in the dataset into a pandas dataframe object.\n",
    "\n",
    "For the following segments the code snippets were retreved from: https://www.kaggle.com/code/anetakovacheva/interpreting-a-music-genre-classifier\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "input_path = 'data/musicgenre_datafolder'\n",
    "file_path = join(input_path, 'music_genre.csv')\n",
    "\n",
    "music_data = pd.read_csv(file_path)\n",
    "\n",
    "\"\"\"\n",
    "Cleaning and Pre-Processing all of the data\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "There are some duplicated data that needs to be cleaned up\n",
    "\"\"\"\n",
    "music_data.duplicated().any()\n",
    "duplicated = music_data.duplicated()\n",
    "music_data[duplicated]\n",
    "music_data.iloc[9999:10006]\n",
    "music_data.drop([10000, 10001, 10002, 10003, 10004], inplace = True)\n",
    "\n",
    "\"\"\"\n",
    "Removing some columns that don't matter or will complicated the training too much\n",
    "\"\"\"\n",
    "music_data.reset_index(inplace = True)\n",
    "music_data = music_data.drop([\"artist_name\", \"index\", \"instance_id\", \"track_name\", \"obtained_date\"], axis = 1)\n",
    "\n",
    "\"\"\"\n",
    "Normalizing the music data such that it removes invalid values for 'tempo' and converts\n",
    "the column values into a float\n",
    "\"\"\"\n",
    "music_data = music_data.drop(music_data[music_data[\"tempo\"] == \"?\"].index)\n",
    "music_data[\"tempo\"] = music_data[\"tempo\"].astype(\"float\")\n",
    "music_data[\"tempo\"] = np.around(music_data[\"tempo\"], decimals = 2)\n",
    "\n",
    "\"\"\"\n",
    "Encoding the columns that are strings with LabelEncoder since this will mess\n",
    "up the algorithms that require numeric values\n",
    "\"\"\"\n",
    "key_encoder = LabelEncoder()\n",
    "mode_encoder = LabelEncoder()\n",
    "music_data[\"key\"] = key_encoder.fit_transform(music_data[\"key\"])\n",
    "music_data[\"mode\"] = mode_encoder.fit_transform(music_data[\"mode\"])\n",
    "\n",
    "\"\"\"\n",
    "Separating out the column features from the music genre label\n",
    "\"\"\"\n",
    "music_features = music_data.drop(\"music_genre\", axis = 1)\n",
    "music_labels = music_data[\"music_genre\"]\n",
    "\n",
    "print(music_data)\n",
    "print(np.unique(music_labels))\n",
    "print(len(np.unique(music_labels)))\n",
    "\n",
    "\"\"\"\n",
    "Scaling the features out into a scale centered around 0 with a standard deviation of 1\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "music_features_scaled = scaler.fit_transform(music_features)\n",
    "# print(music_features_scaled[0])\n",
    "\n",
    "\"\"\"\n",
    "Splitting the data into Training and Testing Data Sets\n",
    "\"\"\"\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    music_features_scaled, music_labels, test_size = 0.1, stratify = music_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92686cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting up seed values for reproducability\n",
    "\"\"\"\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602d5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the size values for the training and testing dataset\n",
    "\"\"\"\n",
    "size_train_samples = np.shape(train_features)[0]\n",
    "size_test_samples = np.shape(test_features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Actually training the MLP Classifier to generate the graph for the learning graph visualizer.\n",
    "This should utilize the percentage of samples lists that use randomly selected samples of the\n",
    "overall training data. This is so that we can test the accuracy (using cross-validation) across different\n",
    "training data size samples to see at what point the accuracy score stops being affected by the size of the training\n",
    "samples. This is also to see at what point the data might start getting overfit.\n",
    "\n",
    "This is to generate the Accuracy Learning Curve.\n",
    "\"\"\"\n",
    "# Defining hyperparameters here\n",
    "hidden_layer_sizes = [100, 50, 20, 10]\n",
    "activation = 'tanh'\n",
    "learning_rate = 'constant'\n",
    "max_iter = 1 # Setting this to 1 since we want to control the epochs ourselves\n",
    "warm_start = True # This is to stack the training across different epochs\n",
    "\n",
    "number_of_epochs = 50\n",
    "\n",
    "# lists to hold the results of training / validation scores\n",
    "x_axis_list = []\n",
    "avg_train_scores_list_reg = []\n",
    "avg_validation_scores_list_reg = []\n",
    "avg_train_loss_values_reg = []\n",
    "avg_validation_loss_values_reg = []\n",
    "\n",
    "# First declaring the Decision Tree Classifer from scikit-learn\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    learning_rate=learning_rate,\n",
    "    max_iter=max_iter,\n",
    "    warm_start=warm_start,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "for epoch_iteration in range(1, number_of_epochs + 1):\n",
    "    \n",
    "    # cross_val_score doesn't increase across epoch runs for some reason so I need to split it myself\n",
    "    train_data, val_data, train_label, val_label = train_test_split(train_features, train_labels, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    clf.fit(train_data, train_label)\n",
    "    \n",
    "    accuracy_score = clf.score(train_data, train_label)\n",
    "    validation_score = clf.score(val_data, val_label)\n",
    "#     loss_score = clf.loss_\n",
    "    train_loss_score = log_loss(train_label, clf.predict_proba(train_data))\n",
    "    val_loss_score = log_loss(val_label, clf.predict_proba(val_data))\n",
    "    \n",
    "    x_axis_list.append(epoch_iteration)\n",
    "    avg_train_scores_list_reg.append(accuracy_score)\n",
    "    avg_validation_scores_list_reg.append(validation_score)\n",
    "    avg_train_loss_values_reg.append(train_loss_score)\n",
    "    avg_validation_loss_values_reg.append(val_loss_score)\n",
    "    \n",
    "    print(\"=============================================\")\n",
    "    print(\"Run for \" + str(epoch_iteration) + \" epoch\")\n",
    "    print(\"Training Score: \" + str(accuracy_score))\n",
    "    print(\"Validation Score: \" + str(validation_score))\n",
    "#     print(\"Loss Score: \" + str(loss_score))\n",
    "    print(\"Training Loss Score: \" + str(train_loss_score))\n",
    "    print(\"Validation Loss Score: \" + str(val_loss_score))\n",
    "    print(\"=============================================\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running PCA DR on the dataset and then feeding the DR dataset to the neural network.\n",
    "\"\"\"\n",
    "svd_solver = \"full\"\n",
    "pcafinal = PCA(n_components = 10, svd_solver = svd_solver)\n",
    "\n",
    "pcafinal.fit(train_features)\n",
    "\n",
    "x_train_transformed_pca = pcafinal.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fc728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
